import numpy as np
import cv2
import json
import imutils
from imutils.video import VideoStream
import time
#from picamera import PiCamera
from time import sleep
from PIL import Image
import Adafruit_ILI9341 as TFT
import RPi.GPIO as GPIO
GPIO.setmode(GPIO.BCM)
import Adafruit_GPIO.SPI as SPI
from PIL import ImageDraw
from PIL import ImageFont
import os
from os import path
from textblob import TextBlob
from gtts import gTTS

from os.path import join, dirname
from os import environ
from watson_developer_cloud import VisualRecognitionV3

visual_recognition = VisualRecognitionV3('2016-05-20', api_key='5cdc66469259c6a4f2ffa532775ec86741e4f71b')

#camera = PiCamera()

# Raspberry Pi configuration.
DC = 18
RST = 23
SPI_PORT = 0
SPI_DEVICE = 0

font = ImageFont.truetype('fonts/zh-TW.ttf', 21)
# Create TFT LCD display class.
disp = TFT.ILI9341(DC, rst=RST, spi=SPI.SpiDev(SPI_PORT, SPI_DEVICE, max_speed_hz=64000000))
# Initialize display.
disp.begin()

image = Image.open("face.png")
image = image.rotate(180).resize((240, 320))
#image = image.resize((240,320))
#disp.clear((0, 0, 0))
disp.display(image)

# initialize the video stream and allow the cammera sensor to warmup
vs = VideoStream(usePiCamera=1).start()
time.sleep(2.0)

def checkFace(ynWatson = 0):
    global imgsize_w, imgsize_h, facesNow

    frame = vs.read()
    #frame = imutils.resize(frame, width=200, height=267)
    #frame = imutils.rotate(frame, 90)

    #print("Check Faces")
    #face_cascade = cv2.CascadeClassifier('/usr/local/share/OpenCV/haarcascades/haarcascade_frontalface_default.xml')
    #gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)
    #faces = face_cascade.detectMultiScale(gray, 1.3, 5)
    #facesNow = len(faces)
    #print ("Faces = " + str(facesNow))

    #cv2.imwrite("realtime.jpg", frame)
    #image = Image.open('realtime.jpg')
    image = Image.fromarray(frame, mode='RGB')
    image = image.rotate(90)
    image = image.resize((240, 320))
    image = image.transpose(Image.FLIP_LEFT_RIGHT)
    #cv2.imwrite("realtime.jpg", image)
    disp.display(image)
    #print("Check Faces")
    cvimage = cv2.imread("realtime.jpg")
    gray = cv2.cvtColor(cvimage, cv2.COLOR_BGR2GRAY)

    face_cascade = cv2.CascadeClassifier('/usr/local/share/OpenCV/haarcascades/haarcascade_frontalface_default.xml')
    faces = face_cascade.detectMultiScale(
        gray,
        scaleFactor=1.05,
        minNeighbors=1,
        minSize=(30, 30)
    )
    facesNow = len(faces)
    print ("Faces = " + str(facesNow))


    if(facesNow>0):
        if (ynWatson==1):
            with open(join(dirname(__file__), "realtime.jpg"), 'rb') as image_file:
                results = visual_recognition.detect_faces(images_file=image_file)
                print(json.dumps(results))

while True:

	checkFace(0)
	

#IBM
#with open(join(dirname(__file__), "face.png"), 'rb') as image_file:
#	results = visual_recognition.classify(images_file=image_file)
#	results = visual_recognition.detect_faces(images_file=image_file)
#	print(json.dumps(results))
