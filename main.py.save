import numpy as np
import io
import cv2
import json
import imutils
from imutils.video import VideoStream
import time
#from picamera import PiCamera
from picamera.array import PiRGBArray
from picamera import PiCamera

from time import sleep
from PIL import Image
import Adafruit_ILI9341 as TFT
import RPi.GPIO as GPIO
GPIO.setmode(GPIO.BCM)
import Adafruit_GPIO.SPI as SPI
from PIL import ImageDraw
from PIL import ImageFont
import os
from os import path
from textblob import TextBlob
from gtts import gTTS

from os.path import join, dirname
from os import environ
from watson_developer_cloud import VisualRecognitionV3

visual_recognition = VisualRecognitionV3('2016-05-20', api_key='5cdc66469259c6a4f2ffa532775ec86741e4f71b')

#camera = PiCamera()

# Raspberry Pi configuration.
DC = 18
RST = 23
SPI_PORT = 0
SPI_DEVICE = 0

font = ImageFont.truetype('fonts/zh-TW.ttf', 21)
# Create TFT LCD display class.
disp = TFT.ILI9341(DC, rst=RST, spi=SPI.SpiDev(SPI_PORT, SPI_DEVICE, max_speed_hz=64000000))
# Initialize display.
disp.begin()

image = Image.open("face.png")
image = image.rotate(180).resize((240, 320))
#image = image.resize((240,320))
#disp.clear((0, 0, 0))
disp.display(image)

# initialize the video stream and allow the cammera sensor to warmup
#vs = VideoStream(usePiCamera=1).start()
#time.sleep(2.0)

def checkFace(frame, ynWatson = 0):
    image = Image.fromarray(frame, mode='RGB')
    image = frame.rotate(90)
    image = image.resize((240, 320))
    image = image.transpose(Image.FLIP_LEFT_RIGHT)

    disp.display(image)
    #print("Check Faces")
    #cvimage = cv2.imread("realtime.jpg")
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

    face_cascade = cv2.CascadeClassifier('/usr/local/share/OpenCV/haarcascades/haarcascade_frontalface_alt.xml')
    faces = face_cascade.detectMultiScale(
        gray,
        scaleFactor=1.3,
        minNeighbors=4,
        minSize=(20, 20)
    )
    facesNow = len(faces)
    print ("Faces = " + str(facesNow))


    if(facesNow>0):
        if (ynWatson==1):
            with open(join(dirname(__file__), "realtime.jpg"), 'rb') as image_file:
                results = visual_recognition.detect_faces(images_file=image_file)
                print(json.dumps(results))


camera = PiCamera()
camera.resolution = (320, 240)
camera.framerate = 32
rawCapture = PiRGBArray(camera)
time.sleep(0.1)
stream = io.BytesIO()

for frame in camera.capture_continuous(stream, format="bgr", use_video_port=True):
    stream.truncate()
    stream.seek(0)

    checkFace(frame,1 )
	

#IBM
#with open(join(dirname(__file__), "face.png"), 'rb') as image_file:
#	results = visual_recognition.classify(images_file=image_file)
#	results = visual_recognition.detect_faces(images_file=image_file)
#	print(json.dumps(results))
